---

# Kubeflow Spam Detection Pipeline

This repository showcases a **Kubeflow Pipeline** for training and evaluating a spam-detection model using **TF-IDF features** and a **RandomForest classifier**.
It was built as part of my exploration into Kubeflow, focusing on how to compose pipelines from **custom containerised components**.
This project demonstrates how the entire machine-learning workflow can be orchestrated end-to-end using Kubeflow.

---

## üöÄ Quick Overview

* **Goal**: Build an end-to-end ML pipeline on Kubeflow for SMS spam detection
* **Pipeline Steps**:

  1. Data Ingestion
  2. Preprocessing (cleaning, encoding, stemming)
  3. Feature Engineering (TF-IDF)
  4. Model Training (RandomForest)
  5. Evaluation (Accuracy, Precision, Recall, AUC)
* **Tech Used**: Kubeflow, Docker, Python, Scikit-learn, Pandas
* **Why It Matters**: Demonstrates containerised ML workflows, parameterisation, and reproducibility

üëâüëâ At a glance, this repo shows how ML pipelines can be structured on Kubeflow, with containerised components and reproducible metric tracking.

---

## üìÇ Repository Structure

| Path                                                                                                                    | Description                                                                   |
| ----------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| [`pipeline.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/pipeline.py)                                   | Kubeflow DSL pipeline definition, compiles to `spam_detection_pipeline.yaml`. |
| [`spam_detection_pipeline.yaml`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/spam_detection_pipeline.yaml) | Compiled pipeline spec, ready for Kubeflow.                                   |
| [`params.yaml`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/params.yaml)                                   | Hyperparameters (train/test split, TF-IDF, RandomForest settings).            |
| [`components/`](https://github.com/PrakashD2003/Kubeflow-Study/tree/main/components)                                    | Contains code + Dockerfiles for each pipeline stage.                          |

**Key Components inside `components/`:**

* [`data-ingestion/ingest.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/components/data-ingestion/ingest.py) ‚Äì dataset loading & splitting
* [`data-preprocessing/preprocess.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/components/data-preprocessing/preprocess.py) ‚Äì text cleaning & label encoding
* [`feature-engineering/feature_engineering.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/components/feature-engineering/feature_engineering.py) ‚Äì TF-IDF feature extraction
* [`train-model/model_training.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/components/train-model/model_training.py) ‚Äì RandomForest training
* [`evaluate-model/model_evaluation.py`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/components/evaluate-model/model_evaluation.py) ‚Äì metrics computation

---

## ‚ñ∂Ô∏è Running the Pipeline

### 1. Clone Repo

```bash
git clone https://github.com/PrakashD2003/Kubeflow-Study.git
cd Kubeflow-Study
```

### 2. Build & Push Images

```bash
docker build -f components/data-ingestion/Dockerfile.ingestion -t <registry>/kubeflow-ingest:latest .
docker push <registry>/kubeflow-ingest:latest
```

*(repeat for preprocess, feature-engineering, train-model, evaluate-model)*

### 3. Configure Parameters

Edit [`params.yaml`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/params.yaml) ‚Üí adjust `test_size`, `max_features`, `n_estimators`.

### 4. Compile Pipeline

```bash
python pipeline.py
```

‚Üí generates [`spam_detection_pipeline.yaml`](https://github.com/PrakashD2003/Kubeflow-Study/blob/main/spam_detection_pipeline.yaml)

### 5. Deploy to Kubeflow

Upload via Kubeflow UI **or** use SDK:

```python
import kfp
client = kfp.Client()
client.create_run_from_pipeline_package('spam_detection_pipeline.yaml')
```

---

## üìä Key Learnings

* Writing container components with Kubeflow DSL
* Orchestrating end-to-end ML workflows
* NLP preprocessing (cleaning, stemming, TF-IDF)
* Training & evaluating RandomForest models
* YAML-driven hyperparameter tuning

---

## üî¨ Detailed Pipeline Breakdown

### 1. Data Ingestion

* Loads SMS dataset ‚Üí drops unused cols ‚Üí renames to `target` & `text`
* Splits into train/test (`test_size` from `params.yaml`)
* Saves CSVs as artifacts

### 2. Preprocessing

* Label encoding of target (`spam` / `ham`)
* Removes duplicates
* Cleans text (lowercase, stopword removal, punctuation stripping, stemming)

### 3. Feature Engineering

* Applies `TfidfVectorizer` with `max_features` from `params.yaml`
* Outputs numerical feature vectors + labels

### 4. Model Training

* Trains `RandomForestClassifier`
* Hyperparams: `n_estimators`, `random_state` from config
* Saves `model.pkl`

### 5. Model Evaluation

* Loads trained model + test set
* Computes **Accuracy, Precision, Recall, AUC**
* Saves metrics as JSON artifact

---

## üîÆ Future Improvements

* Try alternative models (SVM, neural networks) + hyper-parameter tuning
* Add **data versioning & model registry** for governance
* Extend to cross-validation & model comparison
* Package as reusable Kubeflow component for other text classification tasks

---

## üôå Closing Notes

This project is a **hands-on exploration of Kubeflow** for ML workflow orchestration.
It highlights containerised ML pipelines, reproducibility, and modular design.

üëâ [View the Repository on GitHub](https://github.com/PrakashD2003/Kubeflow-Study)

---

